@inproceedings{chen-etal-2025-perceptions,
    abbr = {ACL},
    title = "From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed {LLM}s",
    author = "Chen, Ruxiao  and
      Wang, Chenguang  and
      Sun, Yuran  and
      Zhao, Xilei  and
      Xu, Susu",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.1438/",
    doi = "10.18653/v1/2025.acl-long.1438",
    pages = "29754--29778",
    ISBN = "979-8-89176-251-0",
    abstract = "Evacuation decision prediction is critical for efficient and effective wildfire response by helping emergency management anticipate traffic congestion and bottlenecks, allocate resources, and minimize negative impacts. Traditional statistical methods for evacuation decision prediction fail to capture the complex and diverse behavioral logic of different individuals. In this work, for the first time, we introduce *FLARE*, short for facilitating LLM for advanced reasoning on wildfire evacuation decision prediction, a Large Language Model (LLM)-based framework that integrates behavioral theories and models to streamline the Chain-of-Thought (CoT) reasoning and subsequently integrate with memory-based Reinforcement Learning (RL) module to provide accurate evacuation decision prediction and understanding. Our proposed method addresses the limitations of using existing LLMs for evacuation behavioral predictions, such as limited survey data, mismatching with behavioral theory, conflicting individual preferences, implicit and complex mental states, and intractable mental state-behavior mapping. Experiments on three post-wildfire survey datasets show an average of 20.47{\%} performance improvement over traditional theory-informed behavioral models, with strong cross-event generalizability. Our complete code is publicly available at https://github.com/SusuXu-s-Lab/FLARE"
}

@inproceedings{li-etal-2025-mosaic,
    abbr = {ACL},
    title = "Mosaic-{IT}: Cost-Free Compositional Data Synthesis for Instruction Tuning",
    author = "Li, Ming  and
      Chen, Pei  and
      Wang, Chenguang  and
      Zhao, Hongyu  and
      Liang, Yijun  and
      Hou, YuPeng  and
      Liu, Fuxiao  and
      Zhou, Tianyi",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.1297/",
    doi = "10.18653/v1/2025.findings-acl.1297",
    pages = "25287--25318",
    ISBN = "979-8-89176-256-5",
    abstract = "Finetuning large language models with a variety of instruction-response pairs has enhanced their capability to understand and follow instructions. Current instruction tuning primarily relies on teacher models or human intervention to generate and refine the instructions and responses for training, which are costly, non-sustainable, and may lack diversity. In this paper, we introduce Mosaic Instruction Tuning (Mosaic-IT), a human/model-free compositional data synthesis method that can efficiently create rich and diverse augmentations from existing instruction tuning data to enhance the LLMs. Mosaic-IT randomly concatenates multiple instruction data into one and trains the model to produce the corresponding responses with predefined higher-level meta-instructions to strengthen its multi-step instruction-following and format-following skills. Our extensive evaluations demonstrate a superior performance and training efficiency of Mosaic-IT, which achieves consistent performance improvements over various benchmarks and an 80{\%} reduction in training costs compared with original instruction tuning."
}
